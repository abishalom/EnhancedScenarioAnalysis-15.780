{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import mahalanobis as maha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "- Load Data\n",
    "- Calculate yield curve slope and Y/Y changes in relevant columns\n",
    "\n",
    "\n",
    "#### Data Definitions\n",
    "- TNX: US 10y Treasury\n",
    "- US_Corp: ML US Corporate Bond Total Return Index\n",
    "- LIBOR: 3m LIBOR Rate\n",
    "- BAA: Moody's long-term corporate bond yields index\n",
    "- UNRATE: US seasonally-adjusted unemployment rate\n",
    "- SPY: S\\&P 500 Index\n",
    "- IRX: US 3m treasury rate\n",
    "- RGDP: US seasonally-adjusted Real GDP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Commodity Index Data\n",
    "data = pd.read_csv('data/data.csv', index_col=0)\n",
    "data.index = pd.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Interpolation Forward fill - for GDP data which is quarterly\n",
    "#Could potentially want to only use quarterly data - set lin_interp = False\n",
    "lin_interp = False\n",
    "\n",
    "if lin_interp:\n",
    "    data['RGDP'] = data['RGDP'].interpolate()\n",
    "else:\n",
    "    data = data.dropna(subset = ['RGDP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yield Curve Slope: 10y yields - 3m yields\n",
    "data['YC_Slope'] =  pd.eval('data.TNX - data.IRX')\n",
    "#Credit Spread: long-term BAA (corp bonds) - 10y treasury rate\n",
    "data['Cred_Spread'] = pd.eval('data.BAA - data.TNX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in Y/Y changes\n",
    "YY_cols = ['CPI', 'RGDP']\n",
    "data[[x + '_Growth' for x in YY_cols]] = data[YY_cols]/data[YY_cols].shift(1) - 1\n",
    "\n",
    "#Drop null rows\n",
    "data = data.dropna()\n",
    "\n",
    "#Subtract mean\n",
    "# data = data - data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TNX</th>\n",
       "      <th>US_Corp</th>\n",
       "      <th>LIBOR</th>\n",
       "      <th>CPI</th>\n",
       "      <th>BAA</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>SPY</th>\n",
       "      <th>IRX</th>\n",
       "      <th>RGDP</th>\n",
       "      <th>YC_Slope</th>\n",
       "      <th>Cred_Spread</th>\n",
       "      <th>CPI_Growth</th>\n",
       "      <th>RGDP_Growth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-01-01</th>\n",
       "      <td>6.390</td>\n",
       "      <td>626.328571</td>\n",
       "      <td>3.346875</td>\n",
       "      <td>150.1</td>\n",
       "      <td>8.67</td>\n",
       "      <td>7.3</td>\n",
       "      <td>43.93750</td>\n",
       "      <td>2.90</td>\n",
       "      <td>9850.973</td>\n",
       "      <td>3.490</td>\n",
       "      <td>2.280</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-04-01</th>\n",
       "      <td>6.050</td>\n",
       "      <td>656.734762</td>\n",
       "      <td>3.226562</td>\n",
       "      <td>151.4</td>\n",
       "      <td>8.14</td>\n",
       "      <td>7.1</td>\n",
       "      <td>44.03125</td>\n",
       "      <td>2.91</td>\n",
       "      <td>9908.347</td>\n",
       "      <td>3.140</td>\n",
       "      <td>2.090</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>0.005824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-07-01</th>\n",
       "      <td>5.830</td>\n",
       "      <td>675.154091</td>\n",
       "      <td>3.294034</td>\n",
       "      <td>152.3</td>\n",
       "      <td>7.93</td>\n",
       "      <td>6.9</td>\n",
       "      <td>44.84375</td>\n",
       "      <td>3.03</td>\n",
       "      <td>9955.641</td>\n",
       "      <td>2.800</td>\n",
       "      <td>2.100</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.004773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-10-01</th>\n",
       "      <td>5.388</td>\n",
       "      <td>703.442273</td>\n",
       "      <td>3.386905</td>\n",
       "      <td>153.4</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.8</td>\n",
       "      <td>46.84375</td>\n",
       "      <td>3.03</td>\n",
       "      <td>10091.049</td>\n",
       "      <td>2.358</td>\n",
       "      <td>1.922</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.013601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-01-01</th>\n",
       "      <td>5.638</td>\n",
       "      <td>703.320952</td>\n",
       "      <td>3.271875</td>\n",
       "      <td>154.5</td>\n",
       "      <td>7.65</td>\n",
       "      <td>6.6</td>\n",
       "      <td>48.21875</td>\n",
       "      <td>2.97</td>\n",
       "      <td>10188.954</td>\n",
       "      <td>2.668</td>\n",
       "      <td>2.012</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>0.009702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TNX     US_Corp     LIBOR    CPI   BAA  UNRATE       SPY   IRX  \\\n",
       "Date                                                                           \n",
       "1993-01-01  6.390  626.328571  3.346875  150.1  8.67     7.3  43.93750  2.90   \n",
       "1993-04-01  6.050  656.734762  3.226562  151.4  8.14     7.1  44.03125  2.91   \n",
       "1993-07-01  5.830  675.154091  3.294034  152.3  7.93     6.9  44.84375  3.03   \n",
       "1993-10-01  5.388  703.442273  3.386905  153.4  7.31     6.8  46.84375  3.03   \n",
       "1994-01-01  5.638  703.320952  3.271875  154.5  7.65     6.6  48.21875  2.97   \n",
       "\n",
       "                 RGDP  YC_Slope  Cred_Spread  CPI_Growth  RGDP_Growth  \n",
       "Date                                                                   \n",
       "1993-01-01   9850.973     3.490        2.280    0.008737     0.001674  \n",
       "1993-04-01   9908.347     3.140        2.090    0.008661     0.005824  \n",
       "1993-07-01   9955.641     2.800        2.100    0.005945     0.004773  \n",
       "1993-10-01  10091.049     2.358        1.922    0.007223     0.013601  \n",
       "1994-01-01  10188.954     2.668        2.012    0.007171     0.009702  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Scenarios\n",
    "\n",
    "- Define a scenario with a boolean string. Make sure to use spaces between operators (for calculation of mahalanobis distances.\n",
    "- Find empirical mean and covariance matrix of the factors in this scenario.\n",
    "- Encode scenario as a vector, then find mahalanobis distance using scenario vector and empirical mean, covariance.\n",
    "- We then convert scenario Mahalanobis distance into likelihood measure:\n",
    "$$ e^{\\frac{-d}{2}}$$\n",
    "- Rescale probabilities to sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scenario_vars(scenario):\n",
    "    #Get the variables in the scenario. Sort alphabetically for consistent replication\n",
    "    return sorted(list(set([v.split(' ')[0] for v in scenario.split(' & ')])))\n",
    "\n",
    "def get_scenario_vector(scenario):\n",
    "    #Get a vector from a scenario.\n",
    "    vector = {}\n",
    "    for v in scenario.split(' & '):\n",
    "        x = v.split(' ')\n",
    "        cn = x[0]\n",
    "        val = x[2]\n",
    "        vector[cn] = float(val)\n",
    "    vector = pd.DataFrame(vector, index = [0])\n",
    "    colnames = get_scenario_vars(scenario)\n",
    "    return vector[colnames].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Weak': 0.8996118267005236, 'Normal': 0.24809954216648772, 'Strong': 0.8634019768227041}\n",
      "{'Weak': 0.4473203007819532, 'Normal': 0.12336427615988071, 'Strong': 0.42931542305816617}\n"
     ]
    }
   ],
   "source": [
    "#Define scenarios, use spaces between operators for ease of parsing.\n",
    "scenarios = {'Weak': 'RGDP_Growth = 0.01 & UNRATE = 6', \n",
    "             'Normal': 'UNRATE = 3',\n",
    "             'Strong': 'RGDP_Growth = 0.3'}\n",
    "\n",
    "likelihoods = {}\n",
    "l_sum = 0.0\n",
    "\n",
    "for scenario_name, scenario in scenarios.items():\n",
    "    #Get relevant variables for scenario defined above\n",
    "    scenario_vars = get_scenario_vars(scenario)\n",
    "\n",
    "    #Get the empirical mean & correlation matrix of scenario vars\n",
    "    v = data[scenario_vars].mean().values\n",
    "    scen_corr = data[scenario_vars].corr()\n",
    "\n",
    "    #Encode the scenario as a vector\n",
    "    u = get_scenario_vector(scenario)\n",
    "\n",
    "    #Mahalanobis distance, converted to likelihood\n",
    "    l = np.exp(-maha(u, v, scen_corr)/2)\n",
    "    likelihoods[scenario_name] = l\n",
    "    l_sum += l\n",
    "\n",
    "probs = {sn: l/l_sum for sn, l in likelihoods.items()}\n",
    "print(likelihoods)\n",
    "print(probs)\n",
    "# print(mahala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario = 'RGDP_Growth = 0.01 & UNRATE = 6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1993-01-01    0.007402\n",
       "1993-04-01    0.008183\n",
       "1993-07-01    0.009043\n",
       "1993-10-01    0.009513\n",
       "1994-01-01    0.010511\n",
       "1994-04-01    0.011619\n",
       "1994-07-01    0.013492\n",
       "1994-10-01    0.015674\n",
       "1995-01-01    0.014360\n",
       "1995-04-01    0.015669\n",
       "1995-07-01    0.015091\n",
       "1995-10-01    0.013657\n",
       "1996-01-01    0.014356\n",
       "1996-04-01    0.014343\n",
       "1996-07-01    0.013654\n",
       "1996-10-01    0.011751\n",
       "1997-01-01    0.012357\n",
       "1997-04-01    0.011172\n",
       "1997-07-01    0.010112\n",
       "1997-10-01    0.009153\n",
       "1998-01-01    0.008706\n",
       "1998-04-01    0.007493\n",
       "1998-07-01    0.008279\n",
       "1998-10-01    0.008277\n",
       "1999-01-01    0.007493\n",
       "1999-04-01    0.007494\n",
       "1999-07-01    0.007491\n",
       "1999-10-01    0.006776\n",
       "2000-01-01    0.006453\n",
       "2000-04-01    0.005832\n",
       "                ...   \n",
       "2012-04-01    0.004721\n",
       "2012-07-01    0.004720\n",
       "2012-10-01    0.005764\n",
       "2013-01-01    0.005219\n",
       "2013-04-01    0.006371\n",
       "2013-07-01    0.007406\n",
       "2013-10-01    0.007785\n",
       "2014-01-01    0.010500\n",
       "2014-04-01    0.012841\n",
       "2014-07-01    0.012840\n",
       "2014-10-01    0.015094\n",
       "2015-01-01    0.015092\n",
       "2015-04-01    0.012990\n",
       "2015-07-01    0.011758\n",
       "2015-10-01    0.010641\n",
       "2016-01-01    0.010118\n",
       "2016-04-01    0.010638\n",
       "2016-07-01    0.009625\n",
       "2016-10-01    0.010118\n",
       "2017-01-01    0.009155\n",
       "2017-04-01    0.007880\n",
       "2017-07-01    0.007494\n",
       "2017-10-01    0.006781\n",
       "2018-01-01    0.006782\n",
       "2018-04-01    0.006135\n",
       "2018-07-01    0.006136\n",
       "2018-10-01    0.005839\n",
       "2019-01-01    0.006450\n",
       "2019-04-01    0.005282\n",
       "2019-07-01    0.005553\n",
       "Name: Prob_1, Length: 107, dtype: float64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define scenario, use spaces between operators for ease of parsing.\n",
    "scenario = 'RGDP_Growth = 0.01 & UNRATE = 6'\n",
    "\n",
    "#Get relevant variables from the scenario defined above.\n",
    "scenario_vars = [v.split(' ')[0] for v in scenario.split(' & ')]\n",
    "\n",
    "#Filter data on the above scenario - not sure if useful or not...\n",
    "scen_data = data.query(scenario)[scenario_vars]\n",
    "\n",
    "#Get the empirical mean & correlation matrix of scenario vars\n",
    "v = data[scenario_vars].mean().values\n",
    "scen_corr = data[scenario_vars].corr()\n",
    "\n",
    "#Calculate mahalanobis distance, transform to likelihood measure\n",
    "data['L_1'] = data[scenario_vars].apply(lambda x: np.exp(-maha(x ,v, scen_corr)/2), raw = True, axis = 1)\n",
    "\n",
    "#Rescale for likelihood\n",
    "data['Prob_1'] = data['L_1'].dropna()/data['L_1'].sum()\n",
    "# data['Prob_1'] = data['Prob_1'].fillna(0)\n",
    "data.Prob_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1 = 'RGDP_Growth = 0.01 & UNRATE = 6'\n",
    "scenario_2 = 'RGDP_Growth '\n",
    "\n",
    "# l_1 = np.exp(-maha(np.array([float(v.split(' ')[2]) for v in scenario_1.split(' & ')]), v, scen_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RGDP_Growth', 'UNRATE']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scenario_vars(scenario_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
